{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb42498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mojtabae/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "token = os.getenv('HF_TOKEN')\n",
    "ds_100k = load_dataset(\"GGmorello/FLAMES_results\", \"100k\", token=token)\n",
    "#ds = load_dataset('GGmorello/FLAMES', 'infilled', split='train[:10000]', token=token, cache_dir='/Users/mojtabaeshghie/.cache/hf')#, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe6ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100k = ds_100k['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e806ec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[drop-off] total=31072  both_non_empty=5000  dropped=26072\n",
      "[drop-off] after_norm_nonempty=5000  dropped=0\n",
      "[filters] kept=2964  dropped=2036  flags=(True, True, True, True, True), dedup=norm\n",
      "[dedup] after_dedup=2964\n",
      "[filters] kept=2964  dropped=2036  flags=(True, True, True, True, True), dedup=pair\n",
      "[dedup] after_dedup=2964\n",
      "[filters] kept=2964  dropped=2036  flags=(True, True, True, True, True), dedup=none\n",
      "[dedup] after_dedup=2964\n",
      "[filters] kept=4389  dropped=611  flags=(True, True, True, True, False), dedup=norm\n",
      "[dedup] after_dedup=4389\n",
      "[filters] kept=4389  dropped=611  flags=(True, True, True, True, False), dedup=pair\n",
      "[dedup] after_dedup=4389\n",
      "[filters] kept=4389  dropped=611  flags=(True, True, True, True, False), dedup=none\n",
      "[dedup] after_dedup=4389\n",
      "[filters] kept=4808  dropped=192  flags=(True, True, False, True, False), dedup=norm\n",
      "[dedup] after_dedup=4808\n",
      "[filters] kept=4808  dropped=192  flags=(True, True, False, True, False), dedup=pair\n",
      "[dedup] after_dedup=4808\n",
      "[filters] kept=4808  dropped=192  flags=(True, True, False, True, False), dedup=none\n",
      "[dedup] after_dedup=4808\n",
      "[filters] kept=4980  dropped=20  flags=(True, False, False, True, False), dedup=norm\n",
      "[dedup] after_dedup=4980\n",
      "[filters] kept=4980  dropped=20  flags=(True, False, False, True, False), dedup=pair\n",
      "[dedup] after_dedup=4980\n",
      "[filters] kept=4980  dropped=20  flags=(True, False, False, True, False), dedup=none\n",
      "[dedup] after_dedup=4980\n",
      "[filters] kept=5000  dropped=0  flags=(False, False, False, True, False), dedup=norm\n",
      "[dedup] after_dedup=5000\n",
      "[success] got 5000 rows (>= 5000) with flags=(False, False, False, True, False), dedup=norm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ===================== internals (filtering / scoring) ======================\n",
    "\n",
    "_WS_RE = re.compile(r'\\s+')\n",
    "_PAREN_TRIM_RE = re.compile(r'^\\s*\\((?P<inner>.*)\\)\\s*$', re.DOTALL)\n",
    "\n",
    "def _strip_wrapping_parens(s: str) -> str:\n",
    "    prev, cur = None, (s or \"\").strip()\n",
    "    while prev != cur:\n",
    "        prev = cur\n",
    "        m = _PAREN_TRIM_RE.match(cur)\n",
    "        if not m:\n",
    "            break\n",
    "        cur = m.group('inner').strip()\n",
    "    return cur\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    x = (s or \"\").strip()\n",
    "    if x.endswith(';'):\n",
    "        x = x[:-1]\n",
    "    x = _strip_wrapping_parens(x)\n",
    "    return _WS_RE.sub(' ', x).strip()\n",
    "\n",
    "def _is_effectively_empty(x) -> bool:\n",
    "    \"\"\"Treat None/NaN/empty/placeholder-like as empty; lists/dicts by length.\"\"\"\n",
    "    if x is None:\n",
    "        return True\n",
    "    # pandas NaN\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    # containers\n",
    "    if isinstance(x, (list, tuple, dict, set)):\n",
    "        return len(x) == 0\n",
    "    # strings\n",
    "    s = str(x).strip()\n",
    "    if s == \"\":\n",
    "        return True\n",
    "    if s.lower() in {\"nan\", \"none\", \"null\"}:\n",
    "        return True\n",
    "    if s in {\"[]\", \"{}\"}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# triviality / address checks (operate on normalized text)\n",
    "_ATOM = r'(?:[A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*|\\[[^\\[\\]\\(\\)]*\\])*)|(?:0x[0-9A-Fa-f]+)|(?:\\d+(?:\\s*\\*\\s*1e\\d+)?)'\n",
    "_SIMPLE_CMP_OPS = r'(?:==|!=|<=|>=|<|>)'\n",
    "_FN_CALL_ONLY_RE   = re.compile(r'^\\s*[A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*)*\\s*\\([^()]*\\)\\s*$', re.DOTALL)\n",
    "_IDENT_ONLY_RE     = re.compile(r'^\\s*[A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*|\\[[^\\[\\]\\(\\)]*\\])*\\s*$', re.DOTALL)\n",
    "_NEG_SIMPLE_RE     = re.compile(r'^\\s*!\\s*(?:' + _ATOM + r'|' + r'[A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*)*\\s*\\([^()]*\\))\\s*$', re.DOTALL)\n",
    "_SIMPLE_CMP_RE     = re.compile(r'^\\s*(' + _ATOM + r')\\s*' + _SIMPLE_CMP_OPS + r'\\s*(' + _ATOM + r')\\s*$', re.DOTALL)\n",
    "_HARDCODED_ADDR_RE = re.compile(r'(?:\\baddress\\s*\\(\\s*0x?0\\s*\\)|\\b0x[0-9A-Fa-f]{40}\\b)')\n",
    "\n",
    "def _hardness(s: str) -> float:\n",
    "    bool_ops = s.count('&&') + s.count('||') + s.count('!') * 0.5\n",
    "    arith_ops = len(re.findall(r'(?<!<|>|=)[\\+\\-\\*/%]', s))\n",
    "    cmp_ops = len(re.findall(_SIMPLE_CMP_OPS, s))\n",
    "    parens = s.count('(') + s.count(')')\n",
    "    indexing = s.count('[') + s.count(']')\n",
    "    members = s.count('.')\n",
    "    length = len(s)\n",
    "    fn_calls = len(re.findall(r'[A-Za-z_]\\w*\\s*\\(', s))\n",
    "    return (\n",
    "        2.0*bool_ops +\n",
    "        1.5*arith_ops +\n",
    "        1.5*max(0, cmp_ops-1) +\n",
    "        0.5*parens +\n",
    "        0.4*indexing +\n",
    "        0.3*members +\n",
    "        0.6*fn_calls +\n",
    "        0.01*length\n",
    "    )\n",
    "\n",
    "def _apply_trivial_filters(norm_series: pd.Series,\n",
    "                           drop_addr=True,\n",
    "                           drop_ident_only=True,\n",
    "                           drop_fn_call_only=True,\n",
    "                           drop_neg_simple=True,\n",
    "                           drop_simple_cmp=True) -> pd.Series:\n",
    "    \"\"\"Return boolean mask KEEP (True if survives).\"\"\"\n",
    "    keep = pd.Series(True, index=norm_series.index)\n",
    "    if drop_addr:\n",
    "        keep &= ~norm_series.map(lambda s: bool(_HARDCODED_ADDR_RE.search(s)))\n",
    "    if drop_ident_only:\n",
    "        keep &= ~norm_series.map(lambda s: bool(_IDENT_ONLY_RE.match(s)))\n",
    "    if drop_fn_call_only:\n",
    "        keep &= ~norm_series.map(lambda s: bool(_FN_CALL_ONLY_RE.match(s)))\n",
    "    if drop_neg_simple:\n",
    "        keep &= ~norm_series.map(lambda s: bool(_NEG_SIMPLE_RE.match(s)))\n",
    "    if drop_simple_cmp:\n",
    "        def not_simple_cmp(s: str) -> bool:\n",
    "            if '&&' in s or '||' in s or '?' in s or ':' in s:\n",
    "                return True\n",
    "            if re.search(r'(?<!<|>|=)[\\+\\-\\*/%]', s):\n",
    "                return True\n",
    "            return not bool(_SIMPLE_CMP_RE.match(s))\n",
    "        keep &= norm_series.map(not_simple_cmp)\n",
    "    return keep\n",
    "\n",
    "def _take_in_band(scored: pd.DataFrame, k: int, q_low: float, q_high: float) -> pd.Index:\n",
    "    \"\"\"Return index of picked rows under current band; widen to full range if needed.\"\"\"\n",
    "    if scored.empty:\n",
    "        return scored.index[:0]\n",
    "    lo = scored['hardness'].quantile(q_low) if 0 < q_low < 1 else scored['hardness'].min()\n",
    "    hi = scored['hardness'].quantile(q_high) if 0 < q_high < 1 else scored['hardness'].max()\n",
    "    band = scored[(scored['hardness'] >= lo) & (scored['hardness'] <= hi)]\n",
    "    if len(band) >= k:\n",
    "        return band.sort_values(['hardness', 'norm'], ascending=[False, True]).index[:k]\n",
    "    # widen all the way if short\n",
    "    band = scored\n",
    "    return band.sort_values(['hardness', 'norm'], ascending=[False, True]).index[:k]\n",
    "\n",
    "# ============================= main selector =================================\n",
    "\n",
    "def select_hard_rows_robust(\n",
    "    df: pd.DataFrame,\n",
    "    predicate_col: str = 'predicate',\n",
    "    result_col: str = 'results',\n",
    "    hardness_source: str = 'predicate',   # or 'results'\n",
    "    k: int = 5000,\n",
    "    q_low: float = 0.40,\n",
    "    q_high: float = 0.85,\n",
    "    dedup_mode: str = 'norm',             # 'norm' | 'pair' | 'none'\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Require BOTH predicate & results to be non-empty (robust emptiness check).\n",
    "    2) Score hardness on chosen column (predicate/results) over normalized text.\n",
    "    3) Drop trivial patterns and dedupe (configurable).\n",
    "    4) Select middle-band; if short, progressively relax until reaching k.\n",
    "\n",
    "    Returns the ORIGINAL rows (unchanged) + 'hardness' column.\n",
    "    \"\"\"\n",
    "\n",
    "    if hardness_source not in ('predicate', 'results'):\n",
    "        raise ValueError(\"hardness_source must be 'predicate' or 'results'\")\n",
    "    if predicate_col not in df.columns or result_col not in df.columns:\n",
    "        missing = [c for c in (predicate_col, result_col) if c not in df.columns]\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # -------- Stage 0: both columns non-empty (robust) --------\n",
    "    mask_both = (~df[predicate_col].map(_is_effectively_empty)) & (~df[result_col].map(_is_effectively_empty))\n",
    "    base = df.loc[mask_both].copy()\n",
    "    if verbose:\n",
    "        print(f\"[drop-off] total={len(df)}  both_non_empty={len(base)}  dropped={len(df)-len(base)}\")\n",
    "\n",
    "    if base.empty:\n",
    "        return base.assign(hardness=pd.Series(dtype=float))\n",
    "\n",
    "    # Hardness source\n",
    "    src_col = predicate_col if hardness_source == 'predicate' else result_col\n",
    "\n",
    "    # -------- Stage 1: normalized text (for scoring/filters only) --------\n",
    "    norm = base[src_col].astype(str).map(_norm)\n",
    "    # If normalization empties some rows, drop them\n",
    "    nonempty_norm = norm.str.len() > 0\n",
    "    base = base.loc[nonempty_norm].copy()\n",
    "    norm = norm.loc[nonempty_norm]\n",
    "    if verbose:\n",
    "        print(f\"[drop-off] after_norm_nonempty={len(base)}  dropped={mask_both.sum()-nonempty_norm.sum()}\")\n",
    "\n",
    "    # -------- Stage 2: trivial filters (strict first) --------\n",
    "    # Start strict, then progressively relax if short\n",
    "    drop_flags_list = [\n",
    "        # (addr, ident_only, fn_call_only, neg_simple, simple_cmp)\n",
    "        (True,  True,  True,  True,  True),   # strictest\n",
    "        (True,  True,  True,  True,  False),  # allow simple comparisons\n",
    "        (True,  True,  False, True,  False),  # also allow pure fn calls\n",
    "        (True,  False, False, True,  False),  # also allow identifier-only\n",
    "        (False, False, False, True,  False),  # also allow hardcoded addr\n",
    "        (False, False, False, False, False),  # allow everything (no trivial filter)\n",
    "    ]\n",
    "\n",
    "    # Dedup modes to try if still short\n",
    "    dedup_modes = [dedup_mode] + [m for m in ('pair', 'none', 'norm') if m != dedup_mode]\n",
    "\n",
    "    def build_once(drop_flags, dedup_mode_local):\n",
    "        keep = _apply_trivial_filters(norm,\n",
    "                                      drop_addr=drop_flags[0],\n",
    "                                      drop_ident_only=drop_flags[1],\n",
    "                                      drop_fn_call_only=drop_flags[2],\n",
    "                                      drop_neg_simple=drop_flags[3],\n",
    "                                      drop_simple_cmp=drop_flags[4])\n",
    "        w = base.loc[keep].copy()\n",
    "        n = norm.loc[keep]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[filters] kept={len(w)}  dropped={len(base)-len(w)}  flags={drop_flags}, dedup={dedup_mode_local}\")\n",
    "\n",
    "        if w.empty:\n",
    "            return w.assign(hardness=pd.Series(dtype=float))\n",
    "\n",
    "        # dedup\n",
    "        if dedup_mode_local == 'norm':\n",
    "            dedup_idx = n.reset_index().drop_duplicates(n.name)['index']\n",
    "            w = w.loc[dedup_idx]\n",
    "            n = n.loc[dedup_idx]\n",
    "        elif dedup_mode_local == 'pair':\n",
    "            pair = pd.DataFrame({'p': base.loc[keep, predicate_col].astype(str).values,\n",
    "                                 'r': base.loc[keep, result_col].astype(str).values},\n",
    "                                index=w.index)\n",
    "            dedup_idx = pair.reset_index().drop_duplicates(['p','r'])['index']\n",
    "            w = w.loc[dedup_idx]\n",
    "            n = n.loc[dedup_idx]\n",
    "        elif dedup_mode_local == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"dedup_mode must be 'norm' | 'pair' | 'none'\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[dedup] after_dedup={len(w)}\")\n",
    "\n",
    "        # score\n",
    "        hardness_vals = n.map(_hardness)\n",
    "        scored = pd.DataFrame({'hardness': hardness_vals, 'norm': n}, index=w.index)\n",
    "\n",
    "        # band select (auto widen to full range if short)\n",
    "        picked_idx = _take_in_band(scored, k, q_low, q_high)\n",
    "        selected = w.loc[picked_idx].copy()\n",
    "        selected['hardness'] = scored.loc[picked_idx, 'hardness'].values\n",
    "        return selected\n",
    "\n",
    "    # Try progressively relaxing until we reach k or exhaust\n",
    "    for flags in drop_flags_list:\n",
    "        for dm in dedup_modes:\n",
    "            out = build_once(flags, dm)\n",
    "            if len(out) >= k:\n",
    "                if verbose:\n",
    "                    print(f\"[success] got {len(out)} rows (>= {k}) with flags={flags}, dedup={dm}\")\n",
    "                return out.head(k)\n",
    "\n",
    "    # Last resort: return whatever we could get under the loosest setup\n",
    "    if verbose:\n",
    "        print(f\"[final] could not reach k={k}; returning {len(out)} rows with last flags/dedup.\")\n",
    "    return out\n",
    "\n",
    "# ================================ usage ======================================\n",
    "# Example (as you had, but robust):\n",
    "hard_5k = select_hard_rows_robust(\n",
    "    df_100k,\n",
    "    predicate_col='predicate',\n",
    "    result_col='results',\n",
    "    hardness_source='predicate',  # or 'results'\n",
    "    k=5000, q_low=0.40, q_high=0.85,\n",
    "    dedup_mode='norm',            # try 'pair' if norm is too aggressive\n",
    "    verbose=True\n",
    ")\n",
    "# sanity: both columns are non-empty\n",
    "assert (~hard_5k['predicate'].map(_is_effectively_empty)).all()\n",
    "assert (~hard_5k['results'].map(_is_effectively_empty)).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b3d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_5k.to_csv(\"disl-hardinv.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
